"""
L1 General Manager (GM) â€” Central router, moderator, and summarizer.
"""

from __future__ import annotations

from typing import Any

from src.agents.base import BaseAgent
from src.core.state import SiliconState, DecisionMatrix
from src.core.guards import auto_judge


class GMAgent(BaseAgent):
    ROLE = "gm"
    DISPLAY_NAME = "æ€»ç»ç† (GM)"
    LLM_ROLE = "gm"

    # â”€â”€â”€ Intent Parsing â”€â”€â”€

    async def parse_intent(self, state: SiliconState) -> dict[str, Any]:
        """Parse L0's natural language intent into structured category."""
        await self.initialize()

        prompt = (
            f"åˆ†æä»¥ä¸‹ç”¨æˆ·æ„å›¾ï¼Œè¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼š\n\n"
            f"ç”¨æˆ·æ„å›¾: {state.strategic_intent}\n\n"
            f"è¯·è¿”å›ï¼š\n"
            f'- "intent_category": ä»ä»¥ä¸‹é€‰æ‹©ä¸€ä¸ªï¼š\n'
            f"  NEW_CATEGORY (æ–°èµ›é“/å“ç±»æ¢ç´¢)\n"
            f"  PRODUCT_LAUNCH (å…·ä½“äº§å“ä¸Šæ¶)\n"
            f"  SOURCING (é‡‡è´­/ä¾›åº”å•†ç›¸å…³)\n"
            f"  TECH_FIX (æŠ€æœ¯é—®é¢˜/å·¥å…·ä¿®å¤)\n"
            f"  COMPLEX_STRATEGY (å¤æ‚æˆ˜ç•¥å†³ç­–)\n"
            f'- "mode": EXPLORATION æˆ– EXECUTION\n'
            f'- "meeting_type": EXPLORATION_CHAT, ASYNC_JOINT, æˆ– ADVERSARIAL_HEARING\n'
            f'- "reasoning": ç®€è¦è¯´æ˜åˆ¤æ–­ç†ç”±\n'
        )

        response = await self._llm_think(prompt, {})
        return {"intent_parsed": response}

    def route_mode(self, state: SiliconState) -> str:
        """
        Determine operating mode based on intent category.
        Used as a LangGraph conditional_edge function.
        """
        category = state.intent_category

        if category in ("NEW_CATEGORY", "COMPLEX_STRATEGY"):
            return "exploration"
        elif category == "TECH_FIX":
            return "self_heal"
        else:
            return "execution"

    # â”€â”€â”€ Meeting Moderation â”€â”€â”€

    async def check_convergence(self, state: SiliconState) -> str:
        """
        Check if exploration discussion has converged.
        Returns: "converged" or "continue"
        """
        await self.initialize()

        transcript = "\n".join(
            f"**{t['speaker']}** (Round {t['round']}): {t['content'][:300]}"
            for t in state.meeting_transcript
        )

        prompt = (
            f"ä½œä¸º GMï¼Œåˆ¤æ–­æ­¤è®¨è®ºæ˜¯å¦å·²æ”¶æ•›åˆ°å¯æäº¤çš„ææ¡ˆã€‚\n\n"
            f"## åŸå§‹è®®é¢˜\n{state.strategic_intent}\n\n"
            f"## è®¨è®ºè®°å½•\n{transcript}\n\n"
            f"## åˆ¤æ–­æ ‡å‡†\n"
            f"1. å››æ–¹éƒ½è‡³å°‘å‘è¨€ 1 æ¬¡\n"
            f"2. æ ¸å¿ƒåˆ†æ­§å·²æ˜ç¡®\n"
            f"3. å·²å½¢æˆå¯æäº¤çš„è¡ŒåŠ¨æ–¹æ¡ˆ\n\n"
            f"å›ç­” CONVERGED æˆ– CONTINUEï¼Œé™„ç®€è¦ç†ç”±ã€‚"
        )

        response = await self._llm_think(prompt, {})
        return "converged" if "CONVERGED" in response.upper() else "continue"

    async def aggregate_reviews(self, state: SiliconState) -> dict[str, Any]:
        """
        Aggregate all C-Suite reviews into decision_matrix.
        Used after parallel reviews in Async Joint Session.
        """
        await self.initialize()

        critiques_summary = "\n".join(
            f"**{role.upper()}**: verdict={entry.verdict}, analysis={entry.analysis[:200]}"
            for role, entry in state.critique_logs.items()
        )

        prompt = (
            f"æ±‡æ€»ä»¥ä¸‹ä¸‰ä½é¦–å¸­å®˜çš„å®¡æŸ¥æ„è§ï¼Œç”Ÿæˆç»“æ„åŒ–å†³ç­–çŸ©é˜µã€‚\n\n"
            f"## å®¡æŸ¥ç»“æœ\n{critiques_summary}\n\n"
            f"è¯·è¿”å›ï¼š\n"
            f'- "profit_pct": é¢„ä¼°åˆ©æ¶¦ç‡(%)\n'
            f'- "risk_score": é£é™©åˆ†(1-5)\n'
            f'- "tech_ready": æŠ€æœ¯æ˜¯å¦å°±ç»ª(true/false)\n'
            f'- "consensus": æ˜¯å¦è¾¾æˆå…±è¯†(true/false)\n'
            f'- "summary": ä¸€å¥è¯æ€»ç»“\n'
        )

        response = await self._llm_think(prompt, {})
        return {"aggregation": response}

    def judge_decision(self, state: SiliconState) -> str:
        """
        Apply auto-judge logic to determine next step.
        Returns: "auto_approve" | "revise" | "escalate"
        """
        return auto_judge(state)

    # â”€â”€â”€ Hearing Summary â”€â”€â”€

    async def summarize_hearing(self, state: SiliconState) -> dict[str, Any]:
        """Generate Feishu card content for L0 decision after hearing."""
        await self.initialize()

        transcript = "\n".join(
            f"### Round {t['round']} ({t['speaker']})\n{t['content']}"
            for t in state.meeting_transcript
        )

        prompt = (
            f"å°†ä»¥ä¸‹å¬è¯ä¼šè¾©è®ºæ±‡æ€»ä¸ºé£ä¹¦å†³ç­–å¡ç‰‡å†…å®¹ã€‚\n\n"
            f"## è®®é¢˜\n{state.strategic_intent}\n\n"
            f"## è¾©è®ºå…¨æ–‡\n{transcript}\n\n"
            f"## è¾“å‡ºæ ¼å¼\n"
            f"ğŸ“ˆ CGO è§‚ç‚¹ï¼š[æ‘˜è¦]\n"
            f"ğŸ›¡ï¸ CRO è­¦å‘Šï¼š[æ‘˜è¦]\n"
            f"ğŸ“Š COO æ ¸ç®—ï¼š[æ‘˜è¦]\n"
            f"âš™ï¸ CTO è¯„ä¼°ï¼š[æ‘˜è¦]\n"
        )

        response = await self._llm_think(prompt, {})
        return {"hearing_summary": response}
